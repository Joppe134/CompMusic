---
title: "Storyboard Page"
output: flexdashboard::flex_dashboard

---

Analysis {.storyboard}
=========================================

### Introduction

```{r}
library(tidyverse)
library(shiny)
library(flexdashboard)
library(tidyverse)

library(tidymodels)
library(leaflet)
library(leaflet.extras)
library(cowplot)
library(stringr)
library(ggdendro)
library(heatmaply)
library(tidymodels)
source("compmus.R")



classcorpus <- read_csv("compmus2025.csv")

# Lennart P – beide nummers
lennart_p_1 <- classcorpus %>% filter(str_detect(filename, "^lennart-p-1$"))
lennart_p_2 <- classcorpus %>% filter(str_detect(filename, "^lennart-p-2$"))

# Joppe – eerste nummer
joppe_1 <- classcorpus %>% filter(str_detect(filename, "^joppe-[a-z]-1$"))

# Elze – beide nummers
elze_1 <- classcorpus %>% filter(str_detect(filename, "^elze-[a-z]-1$"))
elze_2 <- classcorpus %>% filter(str_detect(filename, "^elze-[a-z]-2$"))

# AI-generated tracks apart opslaan
joppe_2      <- classcorpus %>% filter(filename == "joppe-h-2")
onni_1       <- classcorpus %>% filter(filename == "onni-q-1")
onni_2       <- classcorpus %>% filter(filename == "onni-q-2")
thomas_2     <- classcorpus %>% filter(filename == "thomas-m-2")
tymon_2      <- classcorpus %>% filter(filename == "tymon-z-2")


```


Track level features
=====================================

Column {.sidebar data-width=300}
-------------------------------------
### Arousal vs Tempo Analysis

The scatterplot comparing arousal vs. tempo reveals key differences between AI-generated and human-composed tracks. hello

Human tracks cluster near the 120 BPM mark, aligning with Moelants’ theory of a preferred tempo for natural movement and listener comfort (Moelants, 2002). Their arousal levels are also moderate, indicating a balance between musical energy and emotional restraint. This may suggest that human composers intuitively modulate arousal to maintain listener engagement without overstimulation.

In contrast, AI-generated tracks show a broader distribution across both dimensions. For instance, tymon-z-2 stands out as an outlier, combining very low tempo (~30 BPM) with low arousal, resulting in a track that might be perceived as lifeless or static. On the opposite end, another AI track combines very high tempo and high arousal, suggesting a lack of pacing control or overcompensation in emotional delivery.

These results support the idea that AI music systems may lack embodied musical intuition, instead generating tracks that explore more extreme emotional-temporal spaces. Human compositions appear more grounded in perceptual and cultural norms, whereas AI music—while often plausible—may neglect subtler dynamics in musical expression.

```{r}


library(tidyverse)

# Combineer je 10 geselecteerde tracks
selected <- bind_rows(
  joppe_1, lennart_p_1, lennart_p_2, elze_1, elze_2,     # Human
  joppe_2, onni_1, onni_2, thomas_2, tymon_2              # AI
) %>%
  mutate(
    origin = rep(c("Human", "AI"), each = 5),
    track = filename
  )

# Maak scatterplot: Arousal vs Tempo
ggplot(selected, aes(x = tempo, y = arousal, color = origin)) +
  geom_point(size = 3) +
  geom_text(aes(label = track), vjust = -1, size = 3) +  # optioneel: labels
  labs(
    title = "Arousal vs Tempo of Selected Tracks",
    x = "Tempo (BPM)",
    y = "Arousal",
    color = "Track Origin"
  ) +
  theme_minimal()

```

```{r}

# Scatterplot: Valence vs Arousal
ggplot(selected, aes(x = valence, y = arousal, color = origin)) +
  geom_point(size = 3) +
  geom_text(aes(label = track), vjust = -1, size = 3) +  # optional labels
  labs(
    title = "Valence vs Arousal of Selected Tracks",
    x = "Valence (Positivity)",
    y = "Arousal (Energy)",
    color = "Track Origin"
  ) +
  theme_minimal()

```

### Discussion

```{r}


```

Details
=========================================

Column
-----------------------------------------

